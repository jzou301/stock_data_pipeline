{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS_DATE: 2025-06-25\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import QuantLib as ql\n",
    "from numba import jit\n",
    "from threading import Thread\n",
    "import date_util\n",
    "import sql_util\n",
    "\n",
    "# Global Variables / Constants\n",
    "db = 'PORTFOLIO_SNAPS'\n",
    "# Start Date: 12/31/2019\n",
    "db_start_date = ql.Date(31, 12, 2019)\n",
    "db_beta_start_date = ql.Date(1, 11, 2016)\n",
    "\n",
    "stock_list_filepath = r'/Users/jenniferzou/Downloads/Stocks Tool/Stocks.xlsx'\n",
    "tickers_input_sheet = 'Portfolio'\n",
    "\n",
    "# Dates\n",
    "Date_Obj = date_util.myDates()\n",
    "\n",
    "pos_date = Date_Obj.get_last_business_day(ql.Date.todaysDate())\n",
    "hist_50d_date = Date_Obj.calendar.advance(pos_date, -50, ql.Days)\n",
    "hist_200d_date = Date_Obj.calendar.advance(pos_date, -200, ql.Days)\n",
    "hist_1m_date = Date_Obj.calendar.advance(pos_date, -1, ql.Months)\n",
    "hist_10y_date = Date_Obj.calendar.advance(pos_date, -10, ql.Years)\n",
    "hist_20y_date = Date_Obj.calendar.advance(pos_date, -20, ql.Years)\n",
    "hist_30y_date = Date_Obj.calendar.advance(pos_date, -30, ql.Years)\n",
    "print(f'POS_DATE: {pos_date.ISO()}')\n",
    "\n",
    "DB_Obj = sql_util.myDB(db)\n",
    "\n",
    "all_sec_info = []\n",
    "all_tech_dfs = []\n",
    "all_fund_dfs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BackFill Stock Data Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_historical_fundamentals_stock_profile(ticker, stock, start_dt, end_dt):\n",
    "   \n",
    "    query = f\"\"\"select * from SEC_INFO where ticker='{ticker}'\"\"\"\n",
    "    sec_info = DB_Obj.read_sql_qry(query)\n",
    "    sec_info.set_index('TICKER', inplace=True)\n",
    "    query = f\"\"\"select POS_DATE, MARKET_CAP from TECHNICAL_SNAPS where ticker='{ticker}'\"\"\"\n",
    "    technical_snaps = DB_Obj.read_sql_qry(query)\n",
    "\n",
    "    df = stock.history(start=start_dt.ISO(), end=end_dt.ISO())\n",
    "    df['POS_DATE'] = df.index.map(lambda x: Date_Obj.timestamp_to_ql(x).ISO())\n",
    "    df['TICKER'] = ticker\n",
    "    stock.financials.T.to_clipboard()\n",
    "    if sec_info.loc[ticker, 'SEC_TYPE'] != 'ETF':\n",
    "        financials = stock.financials.T[['Operating Income', 'Total Revenue',\n",
    "                                         'EBIT', 'Net Interest Income', 'Basic EPS', 'Net Income', 'Interest Expense']]\n",
    "        balance_sheet = stock.balance_sheet.T[['Total Debt','Cash And Cash Equivalents', 'Stockholders Equity', 'Current Assets', 'Inventory', 'Current Liabilities']]\n",
    "        \n",
    "        financials['FYE_DATE'] = financials.index.map(lambda x: Date_Obj.timestamp_to_ql(x).ISO())\n",
    "        df = df.merge(financials, left_on='POS_DATE', right_on='FYE_DATE', how='left')\n",
    "        balance_sheet['FYE_DATE_BS'] = balance_sheet.index.map(lambda x: Date_Obj.timestamp_to_ql(x).ISO())\n",
    "        df = df.merge(balance_sheet, left_on='POS_DATE', right_on='FYE_DATE_BS', how='left')\n",
    "        df = df.merge(technical_snaps, on='POS_DATE', how='left')\n",
    "\n",
    "        df['FYE_DATE'] = df['FYE_DATE'].ffill()\n",
    "        df['EBIT'] = df['EBIT'].ffill()\n",
    "        df['NII'] = df['Net Interest Income'].ffill()\n",
    "\n",
    "        df['Total Debt'] = df['Total Debt'].ffill()\n",
    "        df['Cash And Cash Equivalents'] = df['Cash And Cash Equivalents'].ffill()\n",
    "        df['Net Income'] = df['Net Income'].ffill()\n",
    "        df['Stockholders Equity'] = df['Stockholders Equity'].ffill()\n",
    "        df['Interest Expense'] = df['Interest Expense'].ffill()\n",
    "        df['Operating Income'] = df['Operating Income'].ffill()\n",
    "        df['Total Revenue'] = df['Total Revenue'].ffill()\n",
    "        df['Current Assets'] = df['Current Assets'].ffill()\n",
    "        df['Inventory'] = df['Inventory'].ffill()\n",
    "        df['Current Liabilities'] = df['Current Liabilities'].ffill()\n",
    "\n",
    "        df['EV'] = df['MARKET_CAP'] + df['Total Debt'] - df['Cash And Cash Equivalents']\n",
    "    \n",
    "        df['EPS'] = df['Basic EPS']\n",
    "        df['Annual EPS Growth Rate'] = df['EPS'].pct_change()*100\n",
    "        eps = stock.get_earnings_history()[['epsActual']]\n",
    "        eps['POS_DATE'] = eps.index.map(lambda x: Date_Obj.timestamp_to_ql(x).ISO())\n",
    "        df = df.merge(eps, on='POS_DATE', how='left')\n",
    "        df['EPS'] = np.vectorize(lambda fye, qtr: qtr if qtr != None else fye) (df['epsActual'], df['EPS'])\n",
    "        df['EPS'] = df['EPS'].ffill()\n",
    "        df['Annual EPS Growth Rate'] = df['Annual EPS Growth Rate'].ffill()\n",
    "\n",
    "        df['PE_RATIO'] = df['Close']/df['EPS']\n",
    "        df['PEG_RATIO'] = np.vectorize(lambda pe, eps_growth: pe/eps_growth if eps_growth != 0 else None) \\\n",
    "            (df['PE_RATIO'],df['Annual EPS Growth Rate'])\n",
    "        \n",
    "        df['ROE'] = df['Net Income']/df['Stockholders Equity']\n",
    "        df['DC_RATIO'] = df['Total Debt'] / (df['Total Debt']+df['Stockholders Equity'])    \n",
    "        df['ICR'] = ((df['Net Income'] if 'Financial' in sec_info.loc[ticker, 'SECTOR'] else df['EBIT']) \n",
    "                     / df['Interest Expense']) if sec_info.loc[ticker, 'SEC_TYPE'] == 'EQUITY' else None\n",
    "        df['EV_to_EBIT'] = (df['EV'] / (df['Net Income'] if 'Financial' in sec_info.loc[ticker, 'SECTOR'] else df['EBIT'])) \\\n",
    "                            if sec_info.loc[ticker, 'SEC_TYPE'] == 'EQUITY' else None\n",
    "        df['OPERATING_MARGIN'] = df['Operating Income']/df['Total Revenue']\n",
    "        df['QUICK_RATIO'] = (df['Current Assets']-df['Inventory']) / df['Current Liabilities']\n",
    "        df['FWD_EPS'] = None\n",
    "        df['FWD_PE'] = None\n",
    "        df['ANALYST_RECS'] = None\n",
    "        df['UPLOAD_STAT'] = 'BC'\n",
    "\n",
    "    else:\n",
    "        for col in ['FYE_DATE', 'EV', 'EBIT', 'NII', 'EPS','PE_RATIO', 'PEG_RATIO', \n",
    "                    'ROE', 'DC_RATIO', 'ICR', 'EV_to_EBIT','OPERATING_MARGIN', 'QUICK_RATIO']:\n",
    "            df[f'{col}'] = None\n",
    "\n",
    "    df['FWD_EPS'] = None\n",
    "    df['FWD_PE'] = None\n",
    "    df['ANALYST_RECS'] = None\n",
    "    df['UPLOAD_STAT'] = 'BC'\n",
    "\n",
    "    df = df[['POS_DATE', 'TICKER', 'FYE_DATE', 'EV', 'EBIT', 'NII', 'EPS', \n",
    "               'PE_RATIO', 'PEG_RATIO', 'ROE', 'DC_RATIO', 'ICR', 'EV_to_EBIT',\n",
    "                'OPERATING_MARGIN', 'QUICK_RATIO', 'FWD_EPS', 'FWD_PE', \n",
    "                'ANALYST_RECS', 'UPLOAD_STAT' ]]\n",
    "    all_fund_dfs.append(df)\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_historical_technicals_stock_profile(ticker, stock, start_dt, end_dt, beta_df):\n",
    "    \n",
    "    start_dt_str = Date_Obj.calendar.advance(start_dt, -200, ql.Days).ISO()\n",
    "    end_dt_str = end_dt.ISO()\n",
    "    df = stock.history(start=start_dt_str, end=end_dt_str)\n",
    "    df['POS_DATE'] = df.index.map(lambda x: Date_Obj.timestamp_to_ql(x))\n",
    "    df['TICKER'] = ticker\n",
    "\n",
    "    shares_df = stock.get_shares_full().to_frame(name='SHARES').sort_index()\n",
    "    shares_df['POS_DATE'] = shares_df.index.map(lambda x: Date_Obj.dt_to_ql(x))\n",
    "    df = df.merge(shares_df, on='POS_DATE', how='left')\n",
    "    df['SHARES'] = df['SHARES'].ffill()\n",
    "    df['MARKET_CAP'] = df['SHARES']*df['Close']\n",
    "\n",
    "    df['SMA_50D'] = df[\"Close\"].rolling(window=50).mean()\n",
    "    df['SMA_200D'] = df[\"Close\"].rolling(window=200).mean()\n",
    "    df['EMA_12D'] = df[\"Close\"].ewm(span=12, adjust=False).mean()\n",
    "    df['EMA_26D'] = df[\"Close\"].ewm(span=26, adjust=False).mean()\n",
    "    df['EMA_50D'] = df[\"Close\"].ewm(span=50, adjust=False).mean()\n",
    "    df['EMA_200D'] = df[\"Close\"].ewm(span=200, adjust=False).mean()\n",
    "    df['VMA_20D'] = df['Volume'].rolling(window=20).mean()\n",
    "    df['VMA_50D'] = df['Volume'].rolling(window=50).mean()\n",
    "    df['VMA_200D'] = df['Volume'].rolling(window=200).mean()\n",
    "\n",
    "    df['FOM'] = df['POS_DATE'].apply(lambda x: ql.Date(1, x.month(), x.year()))\n",
    "    df = df.merge(beta_df[['FOM', f'{ticker}_BETA']], on='FOM', how='left')\n",
    "    df['BETA'] = df[f'{ticker}_BETA']\n",
    "    \n",
    "    df['VWMA_50D'] = (df['Close']*df['Volume'].rolling(window=50).sum() / df['Volume'].rolling(window=50).sum())\n",
    "    df['VWMA_200D'] = (df['Close']*df['Volume'].rolling(window=200).sum() / df['Volume'].rolling(window=200).sum())\n",
    "    df['MACD_12D_26D'] = df['EMA_12D']-df['EMA_26D']\n",
    "    delta = df['Close'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    rs = gain.rolling(window=14).mean() / loss.rolling(window=14).mean()\n",
    "    df['RSI_14D'] =  100 - (100 / (1 + rs))\n",
    "    df['UPLOAD_STAT'] = 'BC'\n",
    "    df['POS_DATE'] = df['POS_DATE'].apply(lambda pos_date: pos_date.ISO())\n",
    "\n",
    "    df = df[['POS_DATE', 'TICKER', 'MARKET_CAP', 'Open', 'High', 'Low', 'Close', \n",
    "                'SMA_50D', 'SMA_200D', 'EMA_12D', 'EMA_26D', 'EMA_50D', 'EMA_200D', \n",
    "                'Volume', 'VMA_20D', 'VMA_50D', 'VMA_200D', 'BETA', \n",
    "                'VWMA_50D', 'VWMA_200D', 'MACD_12D_26D', 'RSI_14D', 'UPLOAD_STAT']]\n",
    "    all_tech_dfs.append(df)\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Current Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sec_info_profile(ticker, stock):\n",
    "    info = stock.info\n",
    "    df = {'TICKER': ticker,\n",
    "          'SEC_TYPE': info.get(\"quoteType\", None),\n",
    "          'COMPANY_NAME': info.get('shortName', None), \n",
    "          'SECTOR': info.get('sector', None),\n",
    "          'INDUSTRY': info.get('industry', None)}\n",
    "    df = pd.DataFrame([df])\n",
    "    all_sec_info.append(df)\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_current_technicals_stock_profile(pos_date, ticker, stock):\n",
    "    \n",
    "    info = stock.info\n",
    "    history = stock.history(period=\"1y\")\n",
    "    delta = history['Close'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    rs = gain.rolling(window=14).mean()[-1] / loss.rolling(window=14).mean()[-1]\n",
    "    ema_12d = history['Close'].ewm(span=12, adjust=False).mean()[-1]\n",
    "    ema_26d = history['Close'].ewm(span=26, adjust=False).mean()[-1]\n",
    "\n",
    "    df = {'POS_DATE': pos_date.ISO(),\n",
    "          'TICKER': ticker,\n",
    "          'MARKET_CAP': info.get('marketCap'), \n",
    "          'OPEN': info.get('open'), \n",
    "          'HIGH': info.get('dayHigh'), \n",
    "          'LOW': info.get('dayLow'), \n",
    "          'CLOSE': info.get('previousClose'), \n",
    "          'SMA_50D': info.get('fiftyDayAverage'), \n",
    "          'SMA_200D': info.get('twoHundredDayAverage'), \n",
    "          'EMA_12D': ema_12d,\n",
    "          'EMA_26D': ema_26d,\n",
    "          'EMA_50D': history['Close'].ewm(span=50, adjust=False).mean()[-1],\n",
    "          'EMA_200D': history['Close'].ewm(span=200, adjust=False).mean()[-1],\n",
    "          'VOLUME': info.get('volume'), \n",
    "          'VMA_20D': history['Volume'].rolling(window=20).mean()[-1],\n",
    "          'VMA_50D': history['Volume'].rolling(window=50).mean()[-1],\n",
    "          'VMA_200D': history['Volume'].rolling(window=200).mean()[-1],\n",
    "          'BETA': info.get('beta'),\n",
    "          'VWMA_50D': (history['Close']*history['Volume'].rolling(window=50).sum() / history['Volume'].rolling(window=50).sum())[-1],\n",
    "          'VWMA_200D': (history['Close']*history['Volume'].rolling(window=200).sum() / history['Volume'].rolling(window=200).sum())[-1],\n",
    "          'MACD_12D_26D': ema_12d - ema_26d,\n",
    "          'RSI_14D': 100 - (100 / (1 + rs)),\n",
    "          'UPLOAD_STAT': 'AD' }\n",
    "    df = pd.DataFrame([df])\n",
    "    all_tech_dfs.append(df)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_current_fundamentals_stock_profile(pos_date, ticker, stock):\n",
    "    \n",
    "    info = stock.info\n",
    "    balance_sheet = stock.balance_sheet\n",
    "    financials = stock.financials \n",
    "    sector = info.get('sector', None)\n",
    "    security_type = info.get(\"quoteType\", None)\n",
    "    df = {'POS_DATE': pos_date.ISO(),\n",
    "          'TICKER': ticker,\n",
    "          'FYE_DATE': financials.columns[0] if security_type == 'EQUITY' else None, \n",
    "          'EV': info.get('enterpriseValue'), \n",
    "          'EBIT': (financials.loc['Net Income'].iloc[0] if 'Financial' in sector else financials.loc['EBIT'].iloc[0]) if security_type == 'EQUITY' else None, \n",
    "          'NII': financials.loc['Net Interest Income'].iloc[0] if security_type == 'EQUITY' else None, \n",
    "          'EPS': info.get('trailingEps', None), \n",
    "          'PE_RATIO': info.get('trailingPE', None), \n",
    "          'PEG_RATIO': info.get('trailingPegRatio'),\n",
    "          'ROE': info.get('returnOnEquity'), \n",
    "          'DC_RATIO': balance_sheet.loc['Total Debt'].iloc[0] / (balance_sheet.loc['Total Debt'].iloc[0] + balance_sheet.loc['Stockholders Equity'].iloc[0]) \n",
    "                                          if security_type == 'EQUITY' else None, \n",
    "          'ICR': ((financials.loc['Net Income'].iloc[0] if 'Financial' in sector else financials.loc['EBIT'].iloc[0]) \n",
    "                  / financials.loc['Interest Expense'].iloc[0]) if security_type == 'EQUITY' else None, \n",
    "          'EV_to_EBIT': info.get('enterpriseValue') / (financials.loc['Net Income'].iloc[0] if 'Financial' in sector else financials.loc['EBIT'].iloc[0]) \n",
    "                                          if security_type == 'EQUITY' else None, \n",
    "          'OPERATING_MARGIN': info.get('operatingMargins'), \n",
    "          'QUICK_RATIO': info.get('quickRatio'),\n",
    "          'FWD_EPS': info.get('forwardEps', None),\n",
    "          'FWD_PE': info.get('forwardPE', None), \n",
    "          'ANALYST_RECS': info.get('recommendationMean'),\n",
    "          'UPLOAD_STAT': 'AD' }\n",
    "   \n",
    "    df = pd.DataFrame([df])\n",
    "    all_fund_dfs.append(df)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_fundamental_technical_snaps(pos_date, ticker, stock):\n",
    "    print(f'Stock: {ticker}, {stock}')\n",
    "    # Preliminary Date Check for Yahoo Finance\n",
    "    history = stock.history(period=\"1d\")\n",
    "    if Date_Obj.ql_vs_timestamp(pos_date, history.index[-1]): \n",
    "        load_current_technicals_stock_profile(pos_date, ticker, stock)\n",
    "        load_current_fundamentals_stock_profile(pos_date, ticker, stock)\n",
    "    else:\n",
    "        print(f'YahooFinance may not be updated for current date for ticker {ticker}. Ejecting...')\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_ticker_historical_technical_snaps(pos_date, ticker, stock, beta_df, start_date=db_start_date):\n",
    "    load_sec_info_profile(ticker, stock)\n",
    "    end_date = Date_Obj.calendar.advance(pos_date, -1, ql.Days)\n",
    "    print(f\"Loading historical technicals data for '{ticker}'...\\nStart Date: {start_date}\\nEnd Date: {end_date}\")\n",
    "    load_historical_technicals_stock_profile(ticker, stock, start_date, end_date, beta_df)\n",
    "    load_historical_fundamentals_stock_profile(ticker, stock, start_date, end_date)\n",
    "    return\n",
    "\n",
    "def add_new_ticker_historical_fundamental_snaps(pos_date, ticker, stock, start_date=db_start_date):\n",
    "    end_date = Date_Obj.calendar.advance(pos_date, -1, ql.Days)\n",
    "    print(f\"Loading historical fundamentals data for '{ticker}'...\\nStart Date: {start_date}\\nEnd Date: {end_date}\")\n",
    "    load_historical_fundamentals_stock_profile(ticker, stock, start_date, end_date)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def simple_beta_fn(w, sample=False):\n",
    "    if np.isnan(w).any(): return np.nan\n",
    "    snp = w[:,0]\n",
    "    ticker = w[:,1]\n",
    "    n = len(snp)\n",
    "    if sample: n-=1\n",
    "    x_mean = np.sum(snp) / n\n",
    "    y_mean = np.sum(ticker) / n\n",
    "    cov = np.sum((snp - x_mean) * (ticker - y_mean)) / n\n",
    "    var = np.sum((snp - x_mean) ** 2) / n\n",
    "    if var == 0: return np.nan\n",
    "    return cov/var\n",
    "\n",
    "# https://investexcel.net/how-does-yahoo-finance-calculate-beta/\n",
    "def get_historical_beta(pos_date, new_tickers):\n",
    "    beta_tickers = [\"^GSPC\"]+list(new_tickers)\n",
    "    beta_df_raw = yf.download(beta_tickers, start=db_beta_start_date.ISO(), end=pos_date.ISO(), interval=\"1d\")['Close']\n",
    "    beta_df = beta_df_raw.resample(\"MS\").first()\n",
    "    beta_df['FOM'] = beta_df.index.map(lambda x: Date_Obj.dt_to_ql(x))\n",
    "    for col in beta_tickers:\n",
    "        beta_df[f'LAST_{col}'] = beta_df[col].shift(1)\n",
    "        beta_df[f'{col}_RTN'] = (beta_df[col]-beta_df[f'LAST_{col}'])/beta_df[f'LAST_{col}']\n",
    "    for ticker in new_tickers:\n",
    "        beta_df[f'{ticker}_BETA'] = beta_df[['^GSPC_RTN', f'{ticker}_RTN']].rolling(\n",
    "                                    window=36, min_periods=36, method='table').apply(\n",
    "                                    simple_beta_fn, raw=True, engine='numba')[f'{ticker}_RTN']\n",
    "    return beta_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_portfolio_snaps(pos_date, tickers):\n",
    "    start_time = dt.datetime.now()\n",
    "    query = \"\"\"select distinct ticker from SEC_INFO\"\"\"\n",
    "    all_portfolio_tickers = list(DB_Obj.read_sql_qry(query)['TICKER'])\n",
    "\n",
    "    threads = []\n",
    "    all_tech_dfs, all_fund_dfs = [], []\n",
    "    new_tickers = set(tickers)-set(all_portfolio_tickers)\n",
    "    if len(new_tickers) != 0:\n",
    "        print(\"Adding new tickers in DB...\")\n",
    "        all_new_tickers_stocks = yf.Tickers(new_tickers)\n",
    "        beta_df = get_historical_beta(pos_date, new_tickers)\n",
    "        for ticker in new_tickers:\n",
    "            thread = Thread(target=add_new_ticker_historical_technical_snaps, \n",
    "                            args=(pos_date, ticker, all_new_tickers_stocks.tickers[ticker], beta_df))\n",
    "            threads.append(thread)\n",
    "            thread.start()\n",
    "        for thread in threads:\n",
    "            thread.join() \n",
    "        for info_df, tech_df in list(zip(all_sec_info, tech_df)):\n",
    "            DB_Obj.upload_to_db(info_df, 'SEC_INFO')\n",
    "            DB_Obj.upload_to_db(tech_df, 'TECHNICAL_SNAPS')\n",
    "\n",
    "        for ticker in new_tickers:\n",
    "            thread = Thread(target=add_new_ticker_historical_fundamental_snaps, \n",
    "                            args=(pos_date, ticker, all_new_tickers_stocks.tickers[ticker]))\n",
    "            threads.append(thread)\n",
    "            thread.start()\n",
    "        for thread in threads:\n",
    "            thread.join() \n",
    "        for fund_df in all_fund_dfs:\n",
    "            DB_Obj.upload_to_db(fund_df, 'FUNDAMENTAL_SNAPS')\n",
    "\n",
    "    print(f\"\"\"Adding {pos_date.ISO()} data in DB...\"\"\")\n",
    "    threads = []\n",
    "    all_tech_dfs, all_fund_dfs = [], []\n",
    "    tickers= tickers[0:2]\n",
    "    print(tickers)\n",
    "    all_tickers_stocks = yf.Tickers(tickers)\n",
    "    for ticker in tickers:\n",
    "        thread = Thread(target=upload_fundamental_technical_snaps, \n",
    "                        args=(pos_date, ticker, all_tickers_stocks.tickers[ticker]))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "    for thread in threads:\n",
    "        thread.join() \n",
    "        \n",
    "    for tech_df, fund_df in list(zip(all_tech_dfs, all_fund_dfs)):\n",
    "        print(tech_df, fund_df)\n",
    "        DB_Obj.upload_to_db(tech_df, 'TECHNICAL_SNAPS')\n",
    "        DB_Obj.upload_to_db(fund_df, 'FUNDAMENTAL_SNAPS')\n",
    "\n",
    "    end_time = dt.datetime.now()\n",
    "   \n",
    "    print(f\"Finished Uploading {pos_date.ISO()} in {end_time-start_time} secs!\")\n",
    "    return \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main RUNME: Stock Ticker Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list = list(DB_Obj.read_sql_qry(\"\"\"select distinct TICKER from SEC_INFO order by sec_type, sector, ticker\"\"\").loc[:, 'TICKER'])\n",
    "process_portfolio_snaps(pos_date, ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_info_df = DB_Obj.read_sql_qry(\"\"\"select * from SEC_INFO\"\"\")\n",
    "tech_df = DB_Obj.read_sql_qry(f\"\"\"select * from TECHNICAL_SNAPS order by ticker, pos_date\"\"\")\n",
    "fund_df = DB_Obj.read_sql_qry(f\"\"\"select * from FUNDAMENTAL_SNAPS order by ticker, pos_date\"\"\")\n",
    "with pd.ExcelWriter(\"Daily_Snaps.xlsx\") as writer:  \n",
    "    sec_info_df.to_excel(writer, sheet_name='SEC_INFO')\n",
    "    fund_df.to_excel(writer, sheet_name='FUNDAMENTAL_SNAPS')\n",
    "    tech_df.to_excel(writer, sheet_name='TECHNICAL_SNAPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_Obj.close_conn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
